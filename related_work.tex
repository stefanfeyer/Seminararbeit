\chapter{Related Work}
%In chapter 2 A1, A3, A4, A6, A7, A10, A14 and 15 are already discussed. In this chapter, the remaining aspects are analysed by investigating how other researchers decided on them. The remaining aspects are dependent variables (A2), the task (A5), the MR technology to use (A8), the tracking technology (A9), the behaviour of the instructions (A11), the measures to apply (A12) and the considered body parts (A14). These aspects are better discussed at existing systems to make sure the study has high validity. This chapter is structured employing the perspective \--- though the independent variables, namely ego-centric, exo-centric and the combination of both. In this subchapter, the aspects are discussed and concluded. In the overall conclusion, a decision is made for the aspects by comparing them to each other. eg, the task must be suitable for all perspectives.
\begin{table}[h]
	\centering
	\includegraphics[width=1.0\textwidth]{img/overview_table.png}
	\caption{Related work divided by visual perspectives.}
	\label{tbl:overviewTable}
\end{table}
Table~\ref{tbl:overviewTable} shows the previous work of researchers connected with motor learning in MR. In total there five classes of tasks they used for evaluation. The most common task is \textit{arts}, like Martial Arts or Tai Chi \cite{Han2016, Yang2002, Katzakis2017, Han2017, Portillo2008, Hoang2016, Chua2003, Komura2006}. But also dance movements \cite{Anderson2013a, Yan2015, Chan2010, Chan2007, Hachimura2004}, Sports \cite{Covaci2014, Kojima2014} and rehabilitation tasks \cite{Velloso2013, Chinthammit2014, Tang2015, Rajanna2015, Sousa2016} can be found in literature. Finally, some researchers decided to use abstract movements \cite{Sodhi2012, Lieberman2007} to evaluate their system like Anderson et al. \cite{Anderson2013a} who also compared abstract with real-world movements.\\
The above literature can be also clustered into classes of guidance visualisations. The first class uses a person-shaped avatar performing a movement which the student can mimic (references: all mentions publications, except the publications mentioned in the second class). The second class uses variations of indicators like arrows or lines to guide the student \cite{Katzakis2017, Tang2015, Sodhi2012, Covaci2014, Sousa2016}. Noticeable here is, that indicators are only used in scenarios where the guidance visualisation focusses on only a part of the body. For full-body movements indicators are too overwhelming because of providing too much attention points the student has to focus on \cite{Sodhi2012}.\\
Throughout the literature research became clear that five aspects of designing a study for motor learning are important. First, how the perspective is implemented and what technology will be used. Second, what task is suitable for such a study. Third, what type of guidance visualisation to use. This section is structured in by three points of interest: how the guidance visualisation looks like, what degree of realism is suitable for a person-shaped avatar as guidance visualisation or if even feedback is necessary. Fourth, what measures to use and what to measure. And finally, five, what are the implication of the results of other studies for the study here in question. To analyse these five topics, we dive deeply into six works of other researchers, an overview of this works is given in table~\ref{tbl:overviewTable}.
\begin{table}
	\centering
	\includegraphics[width=1.0\textwidth]{img/detail_paper_overview.png}
	\caption{Overview for the related work discussed in detail.}
	\label{tbl:detailOverviewTable}
\end{table}
In the next section, each of these topics are discussed by means of the related work. After each topic, a conclusion is drawn and the parameters for the study are set. With the scope and the parameters for the study in mind, the study design can be found in the next chapter.

\newpage
\section{Implemented Visual Perspective}
%how are they implemented and technology
%---
\begin{table}[h]
	\centering
	\includegraphics[width=1.0\textwidth]{img/tbl1.png}
	\caption{Overview: implemented visual perspectives in the systems.}
	\label{fig:tbl1}
\end{table}
Chua et al. \cite{Chua2003} implemented five different perspectives to teach with \textbf{Tai Chi Trainer}, compare figure~\ref{fig:taichiperspectives}. There are three exo-centric perspectives (figure~\ref{fig:taichiperspectives}a-c) and two ego-centric perspectives combined with exocentric (figure~\ref{fig:taichiperspectives} d,e). In \textbf{One on One} the student stand next to one teacher, which is closest to a real world training scenario, see figure~\ref{fig:taichiperspectives}(a). In condition \--- \textbf{Four Teachers} \--- the student is surrounded by four teachers, with the student in the middle, see figure~\ref{fig:taichiperspectives}(b). The \textbf{Side by Side}, figure~\ref{fig:taichiperspectives}(c), condition shows four pairs of teacher and student in the same formation as in condition (b). The first ego-centric \& exo-centric combination is called \textbf{Superimposition 1}, see figure~\ref{fig:taichiperspectives}(d). Here the formation still remains, but the student in the middle is surrounded by four more students. On each of the student a red wireframe teacher is superimposed. \textbf{Superimposition 2}, figure~\ref{fig:taichiperspectives}(e), is similar to Superimposition 1 and differs only in the visual representation: the student is now a green, transparent wireframe. Chua et al. use no pure ego-centric perspective, but in the latter two conditions the teacher can be seen also from the exo-centric perspective.
\begin{figure}[h!]
	\centering
	\includegraphics[width=1.0\textwidth]{img/taichi_perspectives.png}
	\caption{Implemented visual perspectives by Chua et al. \cite{Chua2003} for Tai Chi Trainer.}
	\label{fig:taichiperspectives}
\end{figure}\\
%---
$ $\\
\textbf{YouMove} by Anderson et al. \cite{Anderson2013a} uses the Microsoft Kinect\footnote{\hyperlink{https://developer.microsoft.com/de-de/windows/kinect}{https://developer.microsoft.com/de-de/windows/kinect}, accessed 10.12.19} to record motions and to track the student. The recorded instruction, as well as the student's movements, are projected on an AR mirror. The special about this mirror is, that the degree of reflection can be alternated by simply adjusting the light in the room. With this, the student can see his own real body as a reflection as well as the projection of a beamer simultaneously. If the room is bright, the student sees only his reflection and in a dark room only the projection is visible.\\ 
\begin{figure}[h!]
	\centering
	\includegraphics[width=1.0\textwidth]{img/YouMove.png}
	\caption{Implemented visual perspectives by Anderson et al. \cite{Anderson2013a} for YouMove.}
	\label{fig:youmovePerspectives}
\end{figure}
YouMove provides multiple stages for the learning process: (1) Demonstration, (2) Posture Guide, (3) Movement Guide, (4) Mirror, (5) On your own. In stages 1-3, the student sees the guidance visualisation in the exo-centric perspective. In (1) the user sees a video of the movement. In stage 2 \& 3 the user is superimposed by a stick figure. Stage 4 \& 5 does not allow a view on the teacher's representation. After each stage, feedback is given. This view provides multiple perspectives for the four keyframes: a stick figure of the teacher and student superimposed, a video of the teacher's demonstration and a video of the moves of the student. Thus, YouMove provides only the exo-centric visual perspective on the guidance visualisation.\\ \\
%---
\textbf{VR Dance Trainer}. Chan et al. \cite{Chan2010} facilitate a 3D screen for rendering the avatars. The student is tracked by an optical motion capturing system. In the first phase (demonstration) only the teacher is shown on the screen. In the second phase (practise) teacher and student can be seen simultaneously, standing side by side. Additionally, both avatars are mirrored, so the exo-centric viewer can observe the avatars from the back and the front at the same time, compare figure~\ref{fig:vrdtPerspectives}. In the final phase (feedback) the student sees the teacher and the student's performance in slow motion side by side.\\ \\
\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{img/VRDanceTrainerPerspective.png}
	\caption{VR Dance Trainer by Chan et al. \cite{Chan2010}}
	\label{fig:vrdtPerspectives}
\end{figure}
%---
\textbf{Onebody} by Hoang et al. \cite{Hoang2016} show the guidance visualisation in an ego-centric perspective, with an HMD. The teacher is projected inside the body of the student, compare figure~\ref{fig:obEgoPersp} and figure~\ref{fig:ob1}. Both teacher and student are tracked by skeletal tracking, using a Microsoft Kinect. The visualisation of the teacher is attached to the hip of the student. To overcome different body sizes, the avatars are normalised and scaled to the size of the student. For a second condition, an exo-centric view is provided with an HMD, too. There the teacher stands in front of the student.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\textwidth]{img/OneBody_ego_persp.png}
	\caption{Ego-centric perspective on the right arm in Onebody \cite{Hoang2016}. Teachers and students arm can be seen in overlay \cite{Hoang2016}.}
	\label{fig:obEgoPersp}
\end{figure}
%---
\\ \textbf{LightGuide} \cite{Sodhi2012} achieved an ego-centric guidance without using an HMD. The student stands beneath a depth camera and a projector. The depth camera tracks the hand of the student. This position is utilised and the guidance visualisation is projected directly on the user's hand, compare figure~\ref{fig:lightguidepersp}. During the evaluation of the system, four conditions used this ego-centric visual perspective. The remaining conditions are shown exo-centric on a screen or directly on the hand.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\textwidth]{img/LightGuide_Persp.png}
	\caption{Ego-centric guidance visualisation on the hand of the student by \cite{Sodhi2012} in LightGuide.}
	\label{fig:lightguidepersp}
\end{figure}
%---
\begin{figure}[h]
	\centering
	\includegraphics[width=1.0\textwidth]{img/physioPersp.png}
	\caption{Top and front view of Physio@Home \cite{Tang2015}.}
	\label{fig:physio_persp}
\end{figure}
\textbf{Physio@Home} by Tang et al. \cite{Tang2015} used a Microsoft Kinect in combination with a screen forming together an augmented reality mirror. The participant stands in front of the screen and is tracked by the Kinect. On the screen, the participant is augmented by movement indicators. The visual perspective on the guidance visualisation is exo-centric. Tang et al. faced the problem, that the front-facing projection lacks 3D queues. Their solution was multi-camera views. A second view is provided from above, aiming to help the participant to maintain a correct angle of the arm. In the study, four conditions were examined: videoSingle, videoMulti, wedgeSingle and wedgeMulti. Here, video and wedge indicate the guidance visualisation, single and multi indicate the numbers of visualisations.

%---
%how are they implemented and technology
\newpage
\subsection{Conclusion}
\begin{figure}[h]
	\centering
	\includegraphics[width=1.0\textwidth]{img/perspectives.png}
	\includegraphics[width=1.0\textwidth]{img/cond_detail.png}
	\caption{Top: all possible visual perspectives given one student and one teacher with a maximum of two representations. Bottom: detailed differences between the conditions.}
	\label{fig:perspectives}
\end{figure}
Given one student and one teacher there are five possible visual perspectives, compare figure~\ref{fig:perspectives} top. Perspective (1) is the ego-centric view like seen in LightGuide \cite{Sodhi2012}, Onebody \cite{Hoang2016} and in the Tai Chi Trainer \cite{Chua2003}. Perspective (2) is the exo-centric visual perspective which in all systems were present. Perspective (3) is a combination of (1) and (2) where the student sees the teacher superimposed on the own body and additionally in front. In perspective (4) the student sees the teacher superimposed by the own body but is not superimposed himself. Finally, the combination of (3) and (4) is shown in perspective (5). Chua et al. used (5) in condition (d) and (e) in their Tai Chi training system.
\begin{tcolorbox}[colback=red!30!white]
In general, all five visual perspectives are interesting to investigate. But (5) promises to overwhelm the student with too much information. Perspective (1) and (2) already were part of of the evaluations in the presented related work. But perspective (3) and (4) were not evaluated isolated. But (3) and (4) are the consequent successor of (1) and (2) and are therefore relevant to evaluate. For this reason, visual perspective 1-4 will be conditions in the proposed study design.
\end{tcolorbox}
Another important lesson learned refers to the \textit{mirror effect}. A student standing in front of the teacher needs to mirror the movement before the student can perform the movement. Means, the teacher rises e.g. the left arm, the student wants to lift the right arm instinctively. Furthermore, given a fixed viewpoint on the teacher can lead to depth perception misinterpretations. E.g., the teacher raises the left arm not straight but a little bit to the side, it is hard to grasp the correct angle of the rising of the arm. Chua et al. overcome this with multiple representations of the teacher surrounding the student, though the student can look on the teacher from different directions, Tang et al. provided a front and top view of the guidance visualisation and Chan et al. show front and back representations of the teacher. For Hoang et al. and Sodhi et al. this was not a problem for their ego-centric perspective. This made clear that in exo-centric visual perspectives, multiple views on the guidance visualisation must be provided.
\begin{tcolorbox}[colback=red!30!white]
To overcome the mirror issue, in the proposed study design, the student can move freely around the guidance visualisation to observe it from multiple viewpoints, which combines the techniques of \cite{Chua2003, Hoang2016, Tang2015}.
\end{tcolorbox}
%There are multiple ways of realising ego-centric, exo-centric or combination perspectives on guidance visualisations. Ego-centric views are realised through the superimposition of the teacher and the student like seen in Tai Chi Trainer and OneBody or projected movement instructions directly on the student like in LightGuide. The first two use an HMD to realise the ego-centric perspective. For the exo-centric perspective, more possibilities exist like an augmented reality mirror (YouMove), screens or 3D screens (Tai Chi Trainer, Physio@Home) or projectors (LightGuide). Exo-centric perspective can also be achieved with HMD's (OneBody, Tai Chi Trainer). One main benefit of HMD's is the easy visualisation of ego-centric and exo-centric perspectives simultaneously. Because of this, I decide to use an HMD for my study. The Tai Chi Trainer achieved the simultaneous perspective by placing the teacher inside the student and outside the student but did not achieve any significant differences in learning performance, but this could be overcome by today's technology. This representation is chosen for the study. In addition, the authors of the paper state the importance of multiple views (Physio@Home, Tai Chi Trainer, YouMove), if the avatar is rendered on 2D screens, because of missing 3D queues. This can be partly overcome within a VE. But to provide multiple angles on the guidance visualisation could still be necessary. Therefore I decided to let the student moving freely around the guidance visualisation. Since other factors like feedback play also a role for the perspective, the exact definition of the perspective to implement is given in the conclusion of this chapter.

\section{Study Task}
\begin{table}[h]
	\centering
	\includegraphics[width=1.0\textwidth]{img/tbl2.png}
	\caption{Overview: tasks used by the systems.}
	\label{fig:tbl2}
\end{table}
%only Task
%---
The task in Chua's \cite{Chua2003} \textbf{Tai Chi trainer} is \--- as the name indicates \--- a Tai Chi motion. A professional Tai Chi trainer was invited to perform a so-called \textit{Tai Chi form} and recorded offline. This \textit{form} was segmented in four ca. 20 seconds long sequences (motion 1-4). "Motion 1 featured simple hand movements and a 90 degree turn to the right; motion 2 had little hand motion, a 180-degree turn of the feet, and some turning of the upper body; motion 3 featured slow hand motions, large movement of the feet, and some turning of the thorax; and motion 4 featured swift hand movement and turning of the thorax and hips but little movement of the feet." \cite{Chua2003}. Error measurements indicated that all motion but motion 1 had the same difficulty, being significantly easier. This movements can be classified as \textit{sequential movements} according to chapter 2 equation~\ref{eq:constanterror}. 40 volunteers conducted the movements in a study to evaluate their system. They randomized the conditions (compare figure~\ref{fig:taichiperspectives} condition a-e) and the motion combinations to minimize learning effects. For each motion and condition pair, the Tai Chi student were asked to match the Tai Chi teachers demonstration during twelve repetitions.\\ \\
%---
\textbf{YouMove} by Anderson et al. \cite{Anderson2013a} is a movement training system, suitable for a vast range of moves. A movement can be recorded and then edited by an authoring tool. After the editing, the movement is added to the internal library, from which it can be chosen by a student. For the study itself, an author or the paper \--- though no professional \--- recorded four movements. Two of them from ballet and two abstract movements. The authors decided to variate the difficulty of the task, namely "the ballet movements [...] were easier to conceptualise and required only moderate movement.", while "the abstract movements were more difficult to perform, as they were a series of postures with no clear structure and required substantial movement." The movements consisted of four keyframes. Keyframes are important points during the movements, determined and set by the person recording a movement.\\ \\
%---
Jacky Chan et al. developed a \textbf{VR Dance trainer} \cite{Chan2010}. For their system, they invited professional Hip-Hop dancers and recorded their movements. The learner of the movement can choose a movement out of a database. One movement lasts around 2 seconds. First, the teacher appears and the student watches the demonstration, while he can adjust the demonstration speed and viewpoint. After that, the student practices the dance moves by mimicking the teacher's avatar. Finally, the student can see a slow-motion replay of the performance. One hole session takes 15 minutes.\\ \\
%---
\textbf{Onebody} by Hoang et al. \cite{Hoang2016} is designed for sports or physical activity training like yoga, dance or martial arts. For the study, they used a Martial Arts movement. Each participant started with a training session in which a remote instructor teaches a posture physically and verbally. Verbal feedback was given and the training repeated until the student was feeling confident. After that, the final posture was recorded. This applied for four postures with different complexities.\\ \\
%---
In contrast to all other systems, \textbf{Lightguide} by Sodhi et al. \cite{Sodhi2012} build purely on abstract movements to evaluate their system. Sodhi et al. focus on single-arm movements, directed by a guidance visualisation on the hand. The participants perform five movements, namely a line, an "N", a square, a circle and a bowed line, compare figure~\ref{fig:lightguide1}a. All movements were performed in three different angles like shown in figure~\ref{fig:lightguide1}b. These movements were performed with six conditions resulting in 90 datasets per participant (6 conditions x 5 path x 3 angles).
\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{img/lightguide_movements.PNG}
	\caption{Movements schema used by \cite{Sodhi2012} in LightGuide.}
	\label{fig:lightguide1}
\end{figure}\\

%---
\textbf{Physio@Home} by Tang et al. \cite{Tang2015} aims to support rehab exercises for patients at home. Tang et al. chose the shoulder segment as study object, because participants could do this movement easily while standing, and the ball-socket joint gives more DOFs than e.g. the knee. In the study itself, 4 tasks had to be completed: straight, angled, elbow and combo.
\begin{itemize}
	\item[straight] "Abduction of arm along the frontal plane up to shoulder level, followed by adduction of arm back to the participant’s side. This is a simple frontal plane exercise.
	Angled."
	\item[angled] "Abduction of the arm at $45^\circ$ from the frontal plane, followed by adduction back to the side. This is an angled variation of the Straight exercise, where interpreting the angle may be difficult."
	\item[elbow] "External rotation of forearm away from the center of the participant’s body until $90^\circ$ from the sagittal plane, followed by an internal rotation back to center. This exercise requires the participant to keep their elbow tucked against their side and is a difficult exercise to understand without depth cues (i.e., with just a frontal view)."
	\item[combo] "Abduction of the arm along the frontal plane up to shoulder level, internal rotation of the arm until pointing forward, followed by an external rotation of the arm back to the frontal plane, and adduction of the arm back to the participant’s side. This is a more complex exercise than the previous three, involving many components."
\end{itemize}

\subsection{Conclusion}
As we see in this section, there is a verity of tasks to evaluate motor learning. Namely, a Tai Chi form (Tai Chi Trainer \cite{Chua2003}), dance movements (YouMove \cite{Anderson2013a} and VR Dance Trainer \cite{Chan2010}), physiological rehab movements (Physio@home \cite{Tang2015}), abstract movements (YouMove, LightGuide \cite{Sodhi2012}) and Martial Arts (Onebody \cite{Hoang2016}). For the latter is to mention that the evaluation aimed for postures and not movements. To gain valid data some choose to have tasks with comparable complexity (\cite{Chua2003, Sodhi2012} and \cite{Anderson2013a} inside Ballet tasks and inside abstract tasks), therefore e.g. one Tai Chi form was taken and split into four sub forms. Physio@home and YouMove (between ballet and abstract) chose to have different complexities of tasks. All but Tai Chi Trainer proofed to be valid for evaluation of movements. But the authors of Tai Chi Trainer see the reason in the hardware performance, which could be overcome with today's technology. All systems but LightGuide aim to be a teaching system for real-world tasks. This thesis aims to evaluate the influence of the perspective on guidance visualisations itself, therefore, both tasks \--- abstract and real-world tasks \--- seem suitable for the proposed study design.
\begin{tcolorbox}[colback=red!30!white]
Chua et al. included four visual perspectives out of the five perspectives taken into account for the proposed study design in chapter 4. This invites to reuse their task. Additionally, this task has a high ecological validity. Tai Chi is also a well established task in studies for motor learning \cite{Komura2006, Anderson2013a, Han2017} Furthermore, for comparing the student's performance of the movement, it is inevitable to use movements with the same complexity. Chua et al. solved this by splitting one Tai Chi form into four subforms resulting in movements with nearly the same complexity. For this reason, the task in the proposed study design will be a split Tai Chi form. 
\end{tcolorbox}

\newpage
\section{Guidance Visualisation}
\begin{table}[h!]
	\centering
	\includegraphics[width=1.0\textwidth]{img/tbl3.png}
	\caption{Overview: guidance visualisations used by the systems.}
	\label{fig:tbl3}
\end{table}
%visual appearance --- shape and colour
%gudance technique
%feedback
%realism degree
Chua et al.'s \textbf{Tai Chi training} scenario take place in pure VR using an HMD. The lessons are conducted in a virtual pergola standing in nature or park environment. In condition a to c (compare figure~\ref{fig:taichiperspectives}), the student and the teacher are rendered as non-transparent, high realism degree avatars. However, in condition d and e, the visual appearance differs. In condition (d) the student is still rendered normally but the teacher is now represented as a red wireframe. Condition (e) was introduced late in the development of the system based on early subject feedback. The students here are rendered as green wireframe avatars and the teacher as red wireframe avatars.\\
In terms of guiding technique, the student is presented the pre-recorded motion of the teacher. The teacher avatar performs the motion in question and the student tries to mimic this motion. During the mimicking process, no feedback is provided to the student. But in condition (d) and (e) the teacher is superimposed on the student's avatar. This can be interpreted as feedback since the difference between the students e.g. arm position and the teacher's arm position can be seen easily.\\ \\
%---
The visualisation of the teacher in \textbf{YouMove} \cite{Anderson2013a} is rendered with low degree of realism \--- only a stick figure in yellow. During the feedback screen after each stage, the student is also rendered as a stick figure but in blue. For teaching, YouMove utilises the above mentioned five training stages. In the first stage (Demonstration), a video of the teacher performing the movements is shown. The student only sees the video and not the reflection of their own body. The second stage (Posture Guide) a video and the stick figure of the student are shown, but still not the own reflection. The student is asked to match the postures at specific keyframes, where the demonstration stops. After matching the posture of a keyframe, the demonstration moves on to the next keyframe. In the third stage (Movement Guide) the demonstration no longer stops at the keyframes. Furthermore, the reflection and the projection are visible simultaneously, the student is superimposed by the teachers stick figure. Stage four (Mirror) is like the name indicates: the student stands in front of the mirror seeing only his reflection but additionally audio queues are provided. In the last stage (On Your Own) even the mirror is removed and the student performs the movements without any guidance.\\
In terms of feedback, Anderson et al. state "[...] the availability and modality of feedback can greatly impact skill acquisition". To match this, feedback is a part of YouMove. During the second stage (Demonstration), red circles indicate misplaced limbs. The bigger the circle the bigger the displacement. Additionally, a side view on the scene is faded in. At the end of each stage, a so-called "summary feedback" is provided. Here both stick figures of the teacher and student are superimposed and a video of both can be seen. Eventually, a score is provided, which will be explained in the next section.\\ \\
%---
Chan et al. (\textbf{VR Dance Trainer}\cite{Chan2010}, compare figure \ref{fig:vrdt}) choose two different visual representation. The teacher is shown as a high realism degree avatar, while the student is shown as a low realism degree stick figure. The students stick figure serves additionally as feedback regarding the student's performance. The body parts are coloured from green (perfect motion match) over yellow (acceptable motion match) to red (poor motion match). In all phases, these visual representations stay consistent. In the first phase (demonstration) no feedback is given, in the second phase (practice) the student gets immediate feedback in the colour code described above. The last phase provides a slow-motion replay showing with feedback in the same colour code. Additionally, the student can get feedback by the scoreboard see figure~\ref{fig:vrdt} right. Here all body parts are shown with a numeric indicator (0-100) how good the motion was performed on the specific body part.
\begin{figure}
	\centering
	\includegraphics[width=0.45\textwidth]{img/VRDanceTrainerPractice.png}
	\includegraphics[width=0.5\textwidth]{img/VRDanceTrainerScoreBoard.png}
	\caption{Left: student (left) and guidance visualisation (right) by \cite{Chan2010} for VR Dance Trainer, right: offline feedback screen ibidem.}
	\label{fig:vrdt}
\end{figure}
%---
%visual appearence --- shape and colour
%gudance technique
%feedback
%realism degree
\newpage
\begin{figure}[h]
	\centering
	\includegraphics[width=0.225\textwidth]{img/onebody1.png}
	\includegraphics[width=0.225\textwidth]{img/onebody2.png}
	\includegraphics[width=0.45\textwidth]{img/onebody3.png}
	\caption{Left: student avatar (blue) and teacher avatar (red). Green limbs are matching limbs. Right: students view on the scene. Onebody \cite{Hoang2016}.}
	\label{fig:ob1}
\end{figure}

\textbf{Onebody} \cite{Hoang2016} use low realism degree avatars. Both, the student and the teacher are visualised by stick figures. The teachers avatar is red, the students avatar is blue. For feedback, if the students joints are matching joints of the teacher, these joints turn from blue to green, like shown in figure~\ref{fig:ob1} left. Figure~\ref{fig:ob1} right shows the scene from the first person perspective.
The guidance itself takes place in real-time. The remote teacher can give instructions by performing the postures. Additionally, verbally the teacher communicates verbally with the student. The student mimics the postures and can compare his joint positions with the positions of the teacher to correct his joints. Hoang et al. compare the performance of the students achieved in Onebody with the performance in three other systems, namely with traditional video-based learning, video conferencing and a 3rd person perspective in VR. The latter is very similar to Onebody but the teacher stands in front of the student. The system differs in exactly one aspect to each other, see figure~\ref{fig:ob2}.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\textwidth]{img/onebody_training_methods.PNG}
	\caption{Training methods and their differences used in the study to evaluate Onebody \cite{Hoang2016}.}
	\label{fig:ob2}
\end{figure}
%---
\newpage
\textbf{LightGuide} \cite{Sodhi2012} compare six guidance visualisations:
\begin{itemize}
	\item Follow Spot: Moving light spot with elevation information. System sets pace.
	\item 3D F-Arrow: 3D arrow indicates the direction to move. System sets pace.
	\item 3D SG-Arrow: 3D arrow indicates the direction to move. User sets pace.
	\item 3D Pathlet: a line indicates the direction to move next. Current position indicated by a red spot. System sets pace.
	\item Video on hand: Instruction video projected on the hand. User sets pace.
	\item Video on screen: Traditional instruction video. User sets pace.
\end{itemize}
The main idea behind a guidance visualisation directly on the student's body itself is that the student can concentrate on the body part in question and not share his attention with an instruction medium. The last condition proofed to be better than the second last, supporting this thesis.
The student gets instant feedback by comparing the indicators with the hand. A larger offset results in stronger indication in real-time.\\
%---

%---
\textbf{Physio@Home} by Tang et al. \cite{Tang2015} use two guidance techniques. In the first, a video shows the movements instructions, the second they called "the wedge". The latter is a 3D plane showing the way of movement with direction indication. As feedback, the current angle of the arm is shown. On figure \ref{fig:physio_persp} "the wedge" is depicted.
%---
%\subsection{Visual Appearance}
%\subsection{Degree of Realism}
%\subsection{Guidance Techniques}
%\subsection{Feedback}

\subsection{Conclusion}
The visual appearance of the guidance visualisations differ. The Tai Chi Trainer, YouMove, VR Dance Trainer and Onebody use person-shaped avatars. These avatars perform a movement and the student mimics these movements. LightGuide and Physio@Home use direction indicators to visualise the movement in question. Movement indicators like arrows are less obtrusive for single body-part movements but become overwhelming for full-body instructions \cite{Sodhi2012}.\\
This work aims to analyse full-body movements, therefore I choose here as visual appearance a person-shaped avatar. The degree of realism of the avatar rage from stick figures to high realistic-looking persons. Since Weber \cite{Weber2018} showed a preference for realistic avatars I hereby choose high realism degree avatars as guidance visualisations.\\
Besides, there is a difference in completion time based on the guidance technique. If the student sees the movement beforehand completion time is significantly lower. If the student grasps the movement by performing it, completion time is significantly higher. A study must ensure that for all conditions the student could see the movement before performing the movement or not. Comparing with the real world, normally the student sees the movement beforehand. This is why my study will provide pre-watching the demonstration of a movement, too.\\
Sodhi et al. state, that it is hard to compare self-paced and system paced movements. To ensure comparability, only system paced movements will be evaluated. This ensures also only to evaluate the precision of movements.\\
In all systems, feedback plays a role. Immediate feedback as well as aftermath feedback (online vs. offline feedback). For comparability, feedback must be consistent over all conditions. This work does claim to provide full training system but an evaluation tool. For this reason, only immediate feedback during learning will be provided.\\
To ensure, that only the visual perspectives and not feedback are evaluated, the same feedback method will be provided in all conditions. I choose here the overlay feedback without colour coding, where the student align his/her body with the body of the teacher avatar.\\
Eventually, all authors point out the importance of scaling. To correctly match teacher and student, the teacher must be scaled to the students body.
\begin{tcolorbox}[colback=red!30!white]
	\begin{itemize}
		\item 	Indicators for full body movements overwhelm the student \cite{Sodhi2012}, therefore a avatar will be used as guidance visualisation.
		\item Weber showed that high realism avatars suit best for the task, therefore the guidance visualisation will be a high realism avatar \cite{Weber2018}.
		\item For comparability of the study conditions, all tasks will be shown before hand and be paced by the system and not the student \cite{Sodhi2012}.
		\item Only immediate feedback will be provided by the overlaying teacher avatar, because feedback is not part of the evaluation.
		\item To overcome the body size differences, the teacher will be scaled to the student's height \cite{Hoang2016, Chan2010, Tang2015}.
		\end{itemize}
\end{tcolorbox}

\newpage
\section{Variables}
\begin{table}[h]
	\centering
	\includegraphics[width=1.0\textwidth]{img/tbl4.png}
	\caption{Overview: used variables to evaluate the systems.}
	\label{fig:tbl4}
\end{table}
%---
In the \textbf{Tai Chi Trainer} by Chua et al. \cite{Chua2003}, the student's task is to mimic the motion of a pre-recorded teacher. The independent variables are the above-mentioned perspectives (conditions a-e) and the motions. The dependent variable is the precision of the performed movement. To measure this precision, twelve bones of the students were tracked, namely: upper and lower arms, hands, upper and lower legs, and feet. The bones are hierarchically structured with a parent and child end. After normalization of the parent's position and bone length, an error was calculated. This error can be seen as the euclidean distance between the teacher's and the student's position of a bone. It is calculated for every frame of the roughly 20 seconds with a rate of 60 fps. The last four out of twelve trials were considered. This measure is an implementation of chapter 2 equation~\ref{eq:constanterror}.
Chua et al. found two major faults in this method of precision determination: yaw shift and time shift. To overcome the first, the initial position of the student was taken into account. The latter was fixed with a time frame comparison of 120 frames. Eventually, this result was normalized with the difficulty (average number of errors per motion) of the motion task. This will be discussed in detail in the master's projects report. In addition, a post-questionnaire was conducted where the students were asked to rate the difficulty of the representations. The results are discussed in the next section.\\ \\
%---
While Chua et al. calculate the error of the performed movement over all tracked limbs, Anderson et al. (\textbf{YouMove}) take one single joint with the greatest error and \--- even more constricting \--- only the keyframe joints (important joints, specified by the teacher) are taken into consideration. The dependent variable is a score between 0 and 10. An offset of 15 cm results in a score of 7.5 and no error results in a score of 10. The offset is simply the Euclidean distance. This error measurement corresponds also to chapter 2 equation~\ref{eq:constanterror}. To overcome time shift errors, a window of 0.5 seconds is added. If the teacher specified that timing is important, this window is halved. If precision is set as important, 15cm offset results in a score of 7.5. "[...] this values are determined by experimentation"\cite{Anderson2013a}.\\ \\
%---
Chan et al. evaluate the student's performance with the \textbf{VR Dance Trainer}. Therefore they specified 19 body parts (compare figure~\ref{fig:vrdt} right) and calculate a score between 0 and 100. The average over the 19 numeric indicators results in the overall performance. Before and after the training session of one move, this score was calculated. Additionally, a post-course survey asked the student specific questions about the system. This survey had the aim to evaluate if the "[...] system is interesting and able to motivate subjects to learn." \cite{Chan2010} and if "[...] the system can provide them an easy way to learn" ibidem.\\ \\
%---
Hoang et al. \cite{Hoang2016} use six different measures to evaluate \textbf{Onebody}. \textit{Accuracy}, \textit{completion time}, \textit{instructors score}, \textit{ease to understand}, \textit{perceived precision} and \textit{preference}. For \textit{accuracy} the angles of limbs of the student and teacher were compared. For \textit{completion time} the time between start and "[...] the student feeling confident" ibidem. was measured, but caps at 2 minutes (compare chapter~\ref{section:timeandspeed}). \textit{Instructors score} is a subjective score of the instructor after each posture. The data for the last three measures were gathered by post questionnaires. These scores were calculated for all four independent variables (video, video conference, 3rd person, Onebody).
\\ \\
Sodhi et al \cite{Sodhi2012} compare in \textbf{LightGuides} five conditions where the instruction are directly on the body of the user with a baseline condition where the instruction is on a screen. To measure the performance of the student, Sodhi et al. developed two measures: movement accuracy and movement times. Movement accuracy describes the absolute euclidean distance from the closest point. Movement times is divided into two sections by the reason that half of the conditions were self-paced and the in other half, the pace was set by the system. For the self-paced conditions, the completion time (compare chapter~\ref{section:timeandspeed}) is taken as a measure, for system paced conditions the time before or after is taken as a measure. The independent variable are the conditions, the dependent variable is performance.\\ \\
%---
\textbf{Physio@Home} by Tang et al. \cite{Tang2015} use three performance measures to evaluate the student's performance. Two distance measures, one for the elbow and one for the hand, and one angle measure for a maximum of rotation. They ignored speed as a measure because they were mainly interested in the precision of the movements. Additionally, two subjective measures were gathered: perceived accuracy and preference for method.

\subsection{Conclusion}
All previously mentioned works use a performance measurement. These measurements itself varies but have a precision score in common. Some \cite{Anderson2013a}\cite{Chan2010}\cite{Tang2015}\cite{Sodhi2012} specify important body parts or give weights on body parts. The error is measured in the euclidean distance. To overcome timing issues, an time frame between teachers and students movement apply. Besides, a second measurement is used: time. Completion time measures the time a student needs to feel confident to perform the movement. As subjective measurements, perceived accuracy and preference of method is widely used. Additionally, Onebody asks the participants to rate the ease to understand. 
\begin{tcolorbox}[colback=red!30!white]
	For the proposed study design a distance-based performance measure with a 0.5s time shift will be used which proofed to be suitable in \cite{Anderson2013a}. Furthermore, a completion time could give objective insights on perceived precision and speed of learning\cite{Anderson2013a}. As subjective scores, ease to understand, preferred method, perceived precision will be taken\cite{Hoang2016}.
\end{tcolorbox}

\newpage
\section{Results}
\begin{table}[h!]
	\centering
	\includegraphics[width=1.0\textwidth]{img/tbl5.png}
	\caption{Overview: results of related work.}
	\label{fig:tbl5}
\end{table}
%---
\textbf{Tai Chi Trainer}. Chua et al. compare different perspectives (conditions a-e) on the teacher and the student. The independent variables are the above-mentioned precision of the student's performance. By comparing the results they found condition (a) (One on One), (b) (Four Teachers), (c) (Side by Side) and (e) (Superimposition 2) aim the same precision. Only (e) (Superimposition 1) aimed significantly worse than the others. At the same time, the questionnaire indicated that the subjective difficulty of condition (d) and (e) (Superimposition 1 and 2) was the highest. "In fact, all of the subjects who tried Superimposition 2 thought it was the most difficult. Interestingly, although subjects considered Superimposition 2 very difficult compared to the other layouts, the average error on that layout was not significantly greater than the other non-superimposed layouts." \cite{Chua2003}. The Authors argue this result as follows:
\begin{itemize}
	\item simultaneously watching the teacher and performing own movements could interfere with each other.\\
	Chua et al. suggest choosing wisely for the task to suit into VR training.
	\item latency and performance correlate strongly. A lower latency could lead to better performance.\\
	Since the Tai Chi Trainer was developed in 2003, there is a large improvement in latency nowadays.
	\item To reduce latency a low polygon count on the high realism degree avatars was used. More polygons could lead to better performance.\\
	The system was run on a Pentium 3 processor. Today's graphics cards and processors are way above this mark, a higher polygon count is easily achievable.
	\item The field of view was very small.\\
	Today's VR HMDs provide a higher field of view (e.g. HTC Vive, 110$^\circ$).
\end{itemize}
%---
Anderson et al. compared \textbf{YouMove} with traditional video training, resulting in the independent variables \textit{YouMove} and \textit{Video}. The study was conducted with eight participants in a two-factor repeated-measures design. Each participant had one ballet and one abstract task with both conditions. \textit{YouMove} scored significantly better than \textit{Video} by a factor of 2.\\ \\
%---
Chan et al. \cite{Chan2010} investigated three topics with the \textbf{VR Dance Trainer}. First the learning outcome, to proof if the student got better with the system. Second, the "Arousing Interest" to investigate whether the system motivates the students to learn. Eventually, they compared the system with a traditional self-learning method. Comparing the baseline score before training with the VR Dance Trainer with the score after the training session proofed a significantly better performance. The post-survey is interpreted by the authors with "Overall speaking, the subjects enjoy learning dance with our proposed system." ibidem. To compare the system with a traditional learning method, a control group conducted the same study only with the demonstration and no feedback. The baseline scores showed no significant difference between the two groups but the post-training scores did. Questionable remains if a recording of a professional dancer rendered as a high realism degree avatar on a 3D screen can be called a traditional dance learning method.\\ \\
%---
\textbf{Onebody} \cite{Hoang2016} proved to be significantly better over the other training measures in terms of \textit{accuracy}. Interestingly, no significant difference was found between the exo-centric 3rd person view and video conference. On the same time, Onebody has a higher \textit{completion time} than the other systems. The instructor's score showed no significance between the methods. Valuable for this work is, that the ego-centric perspective seems to be slightly better to \textit{understand} than the exo-centric perspective, but not significant. Hence, both ego-centric and exo-centric perspectives are significantly harder to understand than the video-based methods. Furthermore, the \textit{perceived precision} ego-centric perspective is significantly higher than the exo-centric perspective, but nearly on the same level as the video conference method. Eventually, Onebody is more \textit{preferred} by the participants of the study than the 3rd person view. Hoang et al. conclude "[...] that synchronous training and 1st person view has a positive effect on posture accuracy."\cite{Hoang2016} If this applies also to movements could be interesting to investigate.\\ \\
%---
The main finding of Sodhi et al. while evaluating \textbf{LightGuide} is an 85\% higher accuracy of ego-centric on body guidance visualisations compared to exo-centric video instructions.
Per student 90 datasets are generated (6 conditions x 5 path x 3 angles). According to the performance measure they applied, the conditions scored (best to worst): Follow Spot $<$ 3D F-Arrow $<$ 3d G-Arrow $<$ 3D Pathlet $<$ Video Hand $<$ Video Screen. Especially the relation between video on screen and video on hand shows the importance of attention during guidance instruction. The instruction on the body-part it self scored better than seeing the instruction on a screen. In terms of \textit{movement times}, both video conditions lead to lower movement times. Sodhi et al. see the reason therefore, that it makes a difference if the student sees the whole path beforehand than or figuring out the movement as they moved along. Additionally, in an interview, participants of the study stated that self-paced guidance is subjectively preferred over system paced. For system paced movement speed, 30mm per second scored best in a pilot test. Further, they suggest, to plan regular recovery rests to exclude fatigue effects.\\ \\
%---
\textbf{Physio@home} by Tang et al. \cite{Tang2015} investigated two subjective measures. The perceived accuracy ranked videoSingle $<$ videoMulti $<$ WedgeSingle $<$ wedgeMulti. The preferred method aimed for no clear preference. The study results show a higher performance with the multi-view perspectives and also the wedge visualisation. The wedge visualisation in combination with multi-view perspective achieved the highest performance. The authors see the reason in the ability to grasp the correct angle is much easier with the multi-view perspective. Furthermore, the "corrective" feedback of the wedge encouraged the participants to correct themself. Tang et al. further state, that visualisations should contain as least as necessary information to not overwhelm the practitioners. 
\subsection{Conclusion}
LightGuide showed that ego-centric guidance performed better than exo-centric. One reason, they see in the shift of attention. When the student can focus on the body part which is to move, the non-shared attention plays a positive role in learning outcome. The ego-centric Onebody system proofed to be better than the exo-centric perspectives. Since Onebody only evaluates posture guidance, it could be interesting to find out if this also applies for movement guidance. Comparing all systems that implemented ego-centric and exo-centric perspectives concludes as following: Onebody and LightGuide achieved better results with the ego-centric view. The Tai Chi Trainer saw no difference between the two perspectives but see the problem in the hardware available in 2003. Covaci et al. (Free Throw Simulator) \cite{Covaci2014} and Kojima et al. (Training Physical Skill) \cite{Kojima2014} implemented both visual perspectives in but could not find a clear preference for one over the other. Hachimura et al. (MR Dance Trainer) \cite{Hachimura2004} and Sousa et al. (SleeveAR) \cite{Sousa2016} did not evaluate the difference between the two visual perspectives. This makes clear, that further investigations on visual perspectives are necessary. This work aims to close this research gap.

\section{Summary}
Chapter 2 defined the scope for this work. With this scope in mind, this chapter defined \--- based on related work \--- the parameters for study design. The parameters are clustered in four main topics: visual perspective, task, guidance visualisation and measures. In terms of guidance visualisation, we saw five possible visual perspectives given one teacher and one student. Four out of five will serve as independent variables for the study. Furthermore, it becomes clear that to overcome the mirror effect, the student must be able to move freely around the guidance visualisation. The task will be adopted from Chua et al.'s Tai Chi Trainer. For the guidance visualisation, a scaled high realism degree avatar will be used and the system paced movement is shown beforehand. Feedback will not be part of the system, but overlying the student's own body with the body of the teacher can be seen as a feedback method. For objective evaluation, euclidean distance-based error measurements and time measurements will be applied. As subjective scores, the ease to understand, perceived precision and preferred method will be gathered. Finally, the results of the discussed related work showed clearly the need for further investigations on the topic of visual perspectives and motor learning.


\begin{comment}

%----------------------------------------------------
\begin{comment}
\section{in detail - Onebody: Remote Posture Guidance System using First Person View in Virtual Environment}

Onebody by Hoang et al. \cite{Reinoso2016} is a VR system for remote posture guidance. 
%Onebody is designed for sports or physical activity training like yoga, dance or martial arts.
The student and the teacher are both tracked by skeletal tracking. The visualisation of this tracking are shown via a VR headset, allowing the student to follow the instruction of the teacher in first person view of the teacher - which means the student "stands inside the body of the teacher". 


When the teacher moves his limbs, the student can see the movement emerging from himself. Now the student can move his own limbs to mimic the movement till the teachers posture is matched. The teacher sees the students limbs likewise allowing him to give instant feedback to the student. Thus, "Onebody provides a medium to deliver body movement instructions for non-collocated instructor and learner." \todo. %The visualisations are attached to the hip but keeps the mapping between the user and corresponding avatar. To overcome different body sizes, the avatars are normalised and scaled to the size of the person seeing the avatars.\\
For transfering data, both the teacher and the student are clients in a server-client system. The clients are sending the their tracking data to the server which is broadcasting it to the clients. The comparison of the limbs for colour coding is performed on the client side. The matching of the limbs is calculated by the position of the single limbs (see equation \eqref{eq:constanterror}) with a threshold of 5cm to reduce jitter and tracking errors. Limbs in question are wrist, elbow, shoulder, hip, knee and ankle. The feedback with colour codes is provided in realtime.\\
With this system hoang et al. designed a user study to evaluate the performance of posture accuracy and user's preference. Their main hypotheses is "\textit{Onebody delivers better posture accuracy than existing remote movement instruction methods}". "Posture accuracy is determined by the extend to which the student can replicate the final posture as instructed and demonstrated by the instructor." In addition, completion time and a subjective score of the instructor are considered.
To test the hypothesis, Onebody was compared with three other remote posture training methods (independent variables): pre recorded video, video conference (Skype), VR 3rd person perspective. Each of the systems differs to Onebody in terms of synchronous interaction, VR medium and perspective see figure~\ref{fig:ob2}.

%The study was a 4x4 within subject. Each participant stated with a training session in which the not collocated instructor teach a posture physically and verbally. Verbal feedback was given the training repeated until the student was confident. After that the final posture was recorded. A set of four of postures with every system were performed with different complexities.\\
The results show a significant difference in accuracy. Onebody performed significantly better in over video conference, 3rd person VR and pre recorded video. Furthermore, the completion time was significantly higher with Onebody as in the other three systems. The subjective score of the instructor showed no significant differences. A post questionnaire indicated that Onebody is harder to understand and use than the other systems, but at the same time it also indicated that Onebody was perceived to be more exact. Participants rated video conference as their most preferred system over Onebody and 3rd person VR.
%--------

Researchers utilised the theory of the last chapter to design MR Motor Learning systems in various ways. They differ in the technology, tasks, perspectives measures etc. In this chapter we analyse these systems to extract valuable insights to design a MR Motor learning System. First we analyse the aspects of MRML systems. After that we take a close look on some systems how they conducted their investigation and their outcome.

\section{Aspects of MR Motor Learning systems}
paper to come:
\begin{itemize}
\item Cruz: Cyclone uppercut
\item Davcev: AR Environment for Dance Learning
\item Chan: Immersive Performance training Tools Using Motion Capture Technology
\item Han: AR-Arm: Augmented Visualization for Guiding Arm Movment in the First-Person Perspective
\item han: My Tai-Chi Coaches: An Augmented-Learning Tool for Practicing Tai-Chi Chuan
\end{itemize}

\subsection{Method}
Jacky Chan et al. \todo created a VR dance training system using an optical motion capturing system to compare the movements performed by the student with movements from the avatar. These movements are presented to the student as a 3D rendering on large screen. The movements of the students are visualised on the same screen as a coloured stick figure. The student mimics these movements and gets instant feedback as well as a feedback as a summary.

In contrast, Onebody by Hoang et al. \todo use a VR headset for a first person remote posture guidance system. 

\subsection{Tasks}
In Chan et al. \todo the dance student is presented a virtual avatar performing dance moves of A-go-go or Hip-Hop style. The avatars movement is based on the motion capturing data of a professional dancer. Onebody \todo is not only restricted to dance moves but also include other posture based sports or physical activities like Yoga or Mixed Martial Arts.

Onebody \todo uses a number of martial arts postures or stances.
\begin{itemize}
\item Onebody: 16 artificial postures not from but like: tai chi, matial arts
\item VR Dance Trainer: dance movements, 15 min for each move
\item you move: various movements to perform. using a whip, baseball, boxing, ballet, dance moves
\item training archived physical skills IVE: physical skills in sport activities, especially baseball pitching
\end{itemize}

\subsection{Measures and variables}
Jacky Chan et al. \todo defined 19 body parts that are considered in the measure of the performance of the dancing student. They name three features to compare the difference between two motions common: joint position, joint velocity and joint angle. Chan investigated which of these features suits most to judge the two dancing motions. The outcome of this investigation names the joint position to have the highest discriminative power. Hence, the joint position suits them best for their evaluation, Chan et al. calculate a score of the position error for each of the defined body parts, as well as an overall score. 

Onebody \todo uses skeletal of the instructor and the student
"Posture accuracy is determined by the extend to which the student can replicate the final posture as instructed and demonstrated as by the instructor." Independent variable: mothods for posture training. dependent variables: performance factors of posture accuracy, completion time, subjective instructor rating, users preference.

\begin{itemize}
\item scientific work, how to measure movements: hachimura et al, yoshimura et al, qian et al, kwon et al, all use joint angles,  (mentioned in: vr dance trainer)
\item onebody: skeletal tracking, how much percent do the postures match? 3d positions of limbs measured: wrist, elbow, shoulder, hip knee ankle. so angle between bones is the main measure for accuracy. additionally a subjective instructor score was recorded. And, completion time, topped by 2 min.
\item VR Dance trainer: there are 3 common features for measuring hte difference between movements: joint position, velocity, angle. they tested which feature descibes movements best: joint position. base line vs post training movements are compared.
\item you move: in each keyframe, score based on the joint with the maximum error, measured in euclidean distance. but only "important joints" are measured. timing errors: 0.5s error on each side of the frame for matching posture. is timing important, the window is reduced to 0.25s. max eucl. distance is linear mapped to a score. 0 error is 10 (max), 10cm is 7.5 what is the score to pass. if precision is important, 10cm needed for pass.
\end{itemize}

\end{comment}